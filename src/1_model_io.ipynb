{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String theory is a theoretical framework in physics that aims to explain the fundamental nature of particles and their interactions by considering these particles as tiny, vibrating strings. It suggests that the fundamental building blocks of the universe are not point-like particles, as traditionally thought, but rather tiny, one-dimensional strings.\n",
      "\n",
      "These strings can vibrate at different frequencies, and each frequency corresponds to a different particle with its own unique properties, such as mass and charge. In this way, string theory provides a more unified description of particles and their interactions compared to traditional particle physics theories, such as the Standard Model.\n",
      "\n",
      "String theory also suggests the existence of extra dimensions beyond the three spatial dimensions that we experience in our everyday lives. These additional dimensions are compactified or curled up at incredibly small scales, making them difficult to detect directly. The idea of extra dimensions is a key feature of string theory, which helps explain certain phenomena, such as the hierarchy problem in particle physics.\n",
      "\n",
      "It is important to note that string theory is still a developing field and has not yet been experimentally confirmed. However, it has led to several important insights and mathematical discoveries, and it continues to be an active area of research in theoretical physics.\n",
      "\n",
      "I hope this provides a basic understanding of string theory. Let me know if you have any more specific questions!\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "with open(\"../config.json\") as fptr:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = json.load(fptr)[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# setup network proxy\n",
    "os.environ[\"http_proxy\"] = \"http://127.0.0.1:7890\"\n",
    "os.environ[\"https_proxy\"] = \"http://127.0.0.1:7890\"\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.9, model=\"gpt-3.5-turbo\")\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"Hi AI, how are you today?\"),\n",
    "    AIMessage(content=\"I'm great thank you. How can I help you?\"),\n",
    "    HumanMessage(content=\"I'd like to understand string theory.\")\n",
    "]\n",
    "\n",
    "res = llm.invoke(messages)\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup=\"Why don't scientists trust atoms?\", punchline='Because they make up everything!')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field, field_validator\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(..., description=\"question to setup a joke\")\n",
    "    punchline: str = Field(..., description=\"answer to resolve the joke\")\n",
    "\n",
    "    @field_validator('setup')\n",
    "    @classmethod\n",
    "    def question_ends_with_question_mark(cls, field: str):\n",
    "        if not field.endswith('?'):\n",
    "            raise ValueError(f\"Badly formed question: {field}\")\n",
    "        return field\n",
    "    \n",
    "parser = PydanticOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "joke_query = \"Tell me a joke.\"\n",
    "model_input  = prompt.format_prompt(query=joke_query)\n",
    "model_output = llm.invoke(model_input.to_string())\n",
    "\n",
    "parser.parse(model_output.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
