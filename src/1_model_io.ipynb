{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String theory is a theoretical framework in physics that aims to describe the fundamental particles and forces of nature. It suggests that the most basic entities in the universe are not point-like particles, but tiny, one-dimensional \"strings\" that vibrate in different ways.\n",
      "\n",
      "In string theory, these tiny strings can vibrate at different frequencies, resulting in different particles and their corresponding properties. For example, a string vibrating at a certain frequency may appear as an electron, while a different vibration frequency may manifest as a photon or a quark.\n",
      "\n",
      "One of the key features of string theory is that it attempts to unify the fundamental forces of nature, including gravity, electromagnetism, and the strong and weak nuclear forces. This unification is achieved by incorporating additional dimensions beyond the familiar three spatial dimensions and one time dimension.\n",
      "\n",
      "String theory also suggests that there may be multiple possible configurations or \"compactifications\" of these extra dimensions, leading to a variety of possible universes with different physical laws and properties. This concept is known as the \"multiverse.\"\n",
      "\n",
      "It's important to note that string theory is still a very active area of research and is considered a candidate for a theory of everything, but it has not yet been conclusively proven.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "with open(\"../config.json\") as fptr:\n",
    "    config = json.load(fptr)\n",
    "    os.environ[\"OPENAI_API_KEY\"]  = config[\"OPENAI_API_KEY\"]\n",
    "    os.environ[\"OPENAI_API_BASE\"] = config[\"OPENAI_API_BASE\"]\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.9, model=\"gpt-3.5-turbo\")\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"Hi AI, how are you today?\"),\n",
    "    AIMessage(content=\"I'm great thank you. How can I help you?\"),\n",
    "    HumanMessage(content=\"I'd like to understand string theory.\")\n",
    "]\n",
    "\n",
    "res = llm.invoke(messages)\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup=\"Why don't scientists trust atoms?\", punchline='Because they make up everything!')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field, field_validator\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(..., description=\"question to setup a joke\")\n",
    "    punchline: str = Field(..., description=\"answer to resolve the joke\")\n",
    "\n",
    "    @field_validator('setup')\n",
    "    @classmethod\n",
    "    def question_ends_with_question_mark(cls, field: str):\n",
    "        if not field.endswith('?'):\n",
    "            raise ValueError(f\"Badly formed question: {field}\")\n",
    "        return field\n",
    "    \n",
    "parser = PydanticOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "joke_query = \"Tell me a joke.\"\n",
    "model_input  = prompt.format_prompt(query=joke_query)\n",
    "model_output = llm.invoke(model_input.to_string())\n",
    "\n",
    "parser.parse(model_output.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
